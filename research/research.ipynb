{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MindMateAI Testings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Administrator\\\\Desktop\\\\Likith_Nithin_Project\\\\MindMate-AI\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Administrator\\\\Desktop\\\\Likith_Nithin_Project\\\\MindMate-AI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\", api_key=os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, so I need to figure out what the capital of Andhra Pradesh is. Hmm, I'm not entirely sure, but I'll try to work it out step by step.\\n\\nFirst, I know that Andhra Pradesh is a state in India. I remember that India has a lot of states, each with their own capitals. I think some of the more well-known state capitals include Mumbai for Maharashtra, Bangalore for Karnataka, and Chennai for Tamil Nadu. But Andhra Pradesh isn't one I hear about as often, so I'm a bit fuzzy on its capital.\\n\\nWait, I think I've heard the name Hyderabad come up a lot. Isn't Hyderabad a major city in India? I believe it's known for its IT industry and maybe some historical sites. But I'm not certain if it's the capital of Andhra Pradesh. I recall that Hyderabad was the capital of a larger region before, maybe when Andhra Pradesh was part of a bigger state.\\n\\nOh, right! There was something about the formation of Telangana. I think in 2014, Telangana was split off from Andhra Pradesh to become a separate state. So, after that split, Hyderabad became the capital of Telangana. But what about Andhra Pradesh? Did it keep Hyderabad as its capital, or did it move elsewhere?\\n\\nI'm a bit confused here. If Hyderabad is now the capital of Telangana, then Andhra Pradesh must have a different capital. I think the new capital was supposed to be a new city. Was it Amaravati? That rings a bell. I remember hearing about Amaravati being developed as the new capital after the split. But I'm not entirely sure if it's fully functional yet or if it's still in development.\\n\\nWait, there's also something about Visakhapatnam being an important city in Andhra Pradesh. Maybe that's a major city, but I don't think it's the capital. I think the capital is specifically Amaravati. Let me try to piece this together.\\n\\nSo, before 2014, Andhra Pradesh included both what is now Telangana and the remaining Andhra Pradesh. Hyderabad was the capital of the undivided state. After the bifurcation, Telangana took Hyderabad as its capital. Andhra Pradesh needed a new capital, so they decided to build a new city called Amaravati. However, I think the development of Amaravati has faced some issues, and I'm not sure if the government has fully moved there yet.\\n\\nI remember reading that there were plans to make Amaravati a world-class city with modern infrastructure, but maybe due to political changes or funding issues, the progress has been slow. So, perhaps Hyderabad is still serving as the de facto capital for Andhra Pradesh, or maybe they have a temporary capital elsewhere.\\n\\nWait, no, I think Andhra Pradesh has been using Hyderabad as its capital temporarily, but the plan is to shift to Amaravati eventually. But I'm not certain about the current status. Maybe in recent years, there have been updates. I think the government might have considered other cities like Visakhapatnam or Vijayawada as possible capitals, but I believe the official decision was to have Amaravati as the capital.\\n\\nTo summarize, I think the capital of Andhra Pradesh is Amaravati, but it's still under development. Hyderabad, being the former capital, might still be hosting some government functions temporarily. However, I'm not entirely sure if Amaravati has been officially declared the capital or if it's still in the process.\\n\\nI should probably double-check this information. From what I remember, the Andhra Pradesh Reorganisation Act of 2014 led to the formation of Telangana, with Hyderabad as its capital. Andhra Pradesh was to have a new capital, which was planned to be Amaravati. However, due to various reasons, including political changes and financial constraints, the development of Amaravati has been slow. In 2019, there were discussions about three capitals for Andhra Pradesh—Amaravati, Visakhapatnam, and Vijayawada—but I'm not sure if that plan went through.\\n\\nSo, putting it all together, I think the official capital is Amaravati, even if the transition is still ongoing. Hyderabad, while historically significant and the capital before the split, is now the capital of Telangana.\\n</think>\\n\\nThe capital of Andhra Pradesh is Amaravati. After the bifurcation of Andhra Pradesh in 2014, which led to the creation of Telangana with Hyderabad as its capital, Andhra Pradesh planned to develop Amaravati as its new capital. Although the development of Amaravati has faced delays and challenges, it remains the officially designated capital. Hyderabad, while historically the capital of the undivided state, is now the capital of Telangana.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1000, 'prompt_tokens': 11, 'total_tokens': 1011, 'completion_time': 4.699984796, 'prompt_time': 0.00056835, 'queue_time': 8.004515819, 'total_time': 4.700553146}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--52690c97-086c-49c4-a509-f38c6b8c4671-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1000, 'total_tokens': 1011})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital of Andhra Pradesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\Likith_Nithin_Project\\MindMate-AI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Machine Learning (ML) Overview**\\n\\nMachine Learning is a subfield of Artificial Intelligence (AI) that enables computers to learn from data without being explicitly programmed. It's a type of algorithm that allows systems to improve their performance on a task by analyzing and interpreting data.\\n\\n**Key Concepts:**\\n\\n1. **Data**: ML relies on large datasets to learn and make predictions or decisions.\\n2. **Model**: A mathematical representation of the relationships between data, used to make predictions or decisions.\\n3. **Training**: The process of adjusting the model's parameters to fit the data, using algorithms like gradient descent or stochastic gradient descent.\\n4. **Testing**: Evaluating the model's performance on a separate dataset to ensure its accuracy and effectiveness.\\n5. **Prediction**: Using the learned model to make predictions or decisions on new, unseen data.\\n\\n**Types of Machine Learning:**\\n\\n1. **Supervised Learning**: The model is trained on labeled data to learn the relationship between inputs and outputs.\\n2. **Unsupervised Learning**: The model is trained on unlabeled data to identify patterns or relationships.\\n3. **Reinforcement Learning**: The model learns through trial and error by interacting with an environment.\\n\\n**Real-World Applications:**\\n\\n1. **Image Recognition**: Facial recognition, object detection, and image classification.\\n2. **Natural Language Processing**: Sentiment analysis, language translation, and text summarization.\\n3. **Recommendation Systems**: Personalized product recommendations and content suggestion.\\n4. **Predictive Maintenance**: Predicting equipment failures and reducing downtime.\\n5. **Self-Driving Cars**: Autonomous vehicles that can navigate and make decisions based on sensor data.\\n\\nIn summary, Machine Learning is a powerful technology that enables computers to learn from data and make predictions or decisions without being explicitly programmed. Its applications are vast and diverse, and it continues to transform industries and improve our daily lives.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"Explain the concept of Machine Learning briefly?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_react_agent in module langgraph.prebuilt.chat_agent_executor:\n",
      "\n",
      "create_react_agent(\n",
      "    model: Union[str, langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], Union[langchain_core.messages.base.BaseMessage, str]]],\n",
      "    tools: Union[Sequence[Union[langchain_core.tools.base.BaseTool, Callable, dict[str, Any]]], langgraph.prebuilt.tool_node.ToolNode],\n",
      "    *,\n",
      "    prompt: Union[langchain_core.messages.system.SystemMessage, str, Callable[[~StateSchema], Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]]], langchain_core.runnables.base.Runnable[~StateSchema, Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]]], NoneType] = None,\n",
      "    response_format: Union[dict, type[pydantic.main.BaseModel], tuple[str, Union[dict, type[pydantic.main.BaseModel]]], NoneType] = None,\n",
      "    pre_model_hook: Union[langchain_core.runnables.base.Runnable[-Input, +Output], Callable[[-Input], +Output], Callable[[-Input], collections.abc.Awaitable[+Output]], Callable[[collections.abc.Iterator[-Input]], collections.abc.Iterator[+Output]], Callable[[collections.abc.AsyncIterator[-Input]], collections.abc.AsyncIterator[+Output]], langchain_core.runnables.base._RunnableCallableSync[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsync[-Input, +Output], langchain_core.runnables.base._RunnableCallableIterator[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsyncIterator[-Input, +Output], collections.abc.Mapping[str, Any], langgraph.utils.runnable._RunnableWithWriter[-Input, +Output], langgraph.utils.runnable._RunnableWithStore[-Input, +Output], langgraph.utils.runnable._RunnableWithWriterStore[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigWriter[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigStore[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigWriterStore[-Input, +Output], NoneType] = None,\n",
      "    post_model_hook: Union[langchain_core.runnables.base.Runnable[-Input, +Output], Callable[[-Input], +Output], Callable[[-Input], collections.abc.Awaitable[+Output]], Callable[[collections.abc.Iterator[-Input]], collections.abc.Iterator[+Output]], Callable[[collections.abc.AsyncIterator[-Input]], collections.abc.AsyncIterator[+Output]], langchain_core.runnables.base._RunnableCallableSync[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsync[-Input, +Output], langchain_core.runnables.base._RunnableCallableIterator[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsyncIterator[-Input, +Output], collections.abc.Mapping[str, Any], langgraph.utils.runnable._RunnableWithWriter[-Input, +Output], langgraph.utils.runnable._RunnableWithStore[-Input, +Output], langgraph.utils.runnable._RunnableWithWriterStore[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigWriter[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigStore[-Input, +Output], langgraph.utils.runnable._RunnableWithConfigWriterStore[-Input, +Output], NoneType] = None,\n",
      "    state_schema: Optional[Type[~StateSchema]] = None,\n",
      "    config_schema: Optional[Type[Any]] = None,\n",
      "    checkpointer: Union[NoneType, bool, langgraph.checkpoint.base.BaseCheckpointSaver] = None,\n",
      "    store: Optional[langgraph.store.base.BaseStore] = None,\n",
      "    interrupt_before: Optional[list[str]] = None,\n",
      "    interrupt_after: Optional[list[str]] = None,\n",
      "    debug: bool = False,\n",
      "    version: Literal['v1', 'v2'] = 'v2',\n",
      "    name: Optional[str] = None\n",
      ") -> langgraph.graph.state.CompiledStateGraph\n",
      "    Creates an agent graph that calls tools in a loop until a stopping condition is met.\n",
      "\n",
      "    For more details on using `create_react_agent`, visit [Agents](https://langchain-ai.github.io/langgraph/agents/overview/) documentation.\n",
      "\n",
      "    Args:\n",
      "        model: The `LangChain` chat model that supports tool calling.\n",
      "        tools: A list of tools or a ToolNode instance.\n",
      "            If an empty list is provided, the agent will consist of a single LLM node without tool calling.\n",
      "        prompt: An optional prompt for the LLM. Can take a few different forms:\n",
      "\n",
      "            - str: This is converted to a SystemMessage and added to the beginning of the list of messages in state[\"messages\"].\n",
      "            - SystemMessage: this is added to the beginning of the list of messages in state[\"messages\"].\n",
      "            - Callable: This function should take in full graph state and the output is then passed to the language model.\n",
      "            - Runnable: This runnable should take in full graph state and the output is then passed to the language model.\n",
      "\n",
      "        response_format: An optional schema for the final agent output.\n",
      "\n",
      "            If provided, output will be formatted to match the given schema and returned in the 'structured_response' state key.\n",
      "            If not provided, `structured_response` will not be present in the output state.\n",
      "            Can be passed in as:\n",
      "\n",
      "                - an OpenAI function/tool schema,\n",
      "                - a JSON Schema,\n",
      "                - a TypedDict class,\n",
      "                - or a Pydantic class.\n",
      "                - a tuple (prompt, schema), where schema is one of the above.\n",
      "                    The prompt will be used together with the model that is being used to generate the structured response.\n",
      "\n",
      "            !!! Important\n",
      "                `response_format` requires the model to support `.with_structured_output`\n",
      "\n",
      "            !!! Note\n",
      "                The graph will make a separate call to the LLM to generate the structured response after the agent loop is finished.\n",
      "                This is not the only strategy to get structured responses, see more options in [this guide](https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/).\n",
      "\n",
      "        pre_model_hook: An optional node to add before the `agent` node (i.e., the node that calls the LLM).\n",
      "            Useful for managing long message histories (e.g., message trimming, summarization, etc.).\n",
      "            Pre-model hook must be a callable or a runnable that takes in current graph state and returns a state update in the form of\n",
      "                ```python\n",
      "                # At least one of `messages` or `llm_input_messages` MUST be provided\n",
      "                {\n",
      "                    # If provided, will UPDATE the `messages` in the state\n",
      "                    \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES), ...],\n",
      "                    # If provided, will be used as the input to the LLM,\n",
      "                    # and will NOT UPDATE `messages` in the state\n",
      "                    \"llm_input_messages\": [...],\n",
      "                    # Any other state keys that need to be propagated\n",
      "                    ...\n",
      "                }\n",
      "                ```\n",
      "\n",
      "            !!! Important\n",
      "                At least one of `messages` or `llm_input_messages` MUST be provided and will be used as an input to the `agent` node.\n",
      "                The rest of the keys will be added to the graph state.\n",
      "\n",
      "            !!! Warning\n",
      "                If you are returning `messages` in the pre-model hook, you should OVERWRITE the `messages` key by doing the following:\n",
      "\n",
      "                ```python\n",
      "                {\n",
      "                    \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES), *new_messages]\n",
      "                    ...\n",
      "                }\n",
      "                ```\n",
      "        post_model_hook: An optional node to add after the `agent` node (i.e., the node that calls the LLM).\n",
      "            Useful for implementing human-in-the-loop, guardrails, validation, or other post-processing.\n",
      "            Post-model hook must be a callable or a runnable that takes in current graph state and returns a state update.\n",
      "\n",
      "            !!! Note\n",
      "                Only available with `version=\"v2\"`.\n",
      "        state_schema: An optional state schema that defines graph state.\n",
      "            Must have `messages` and `remaining_steps` keys.\n",
      "            Defaults to `AgentState` that defines those two keys.\n",
      "        config_schema: An optional schema for configuration.\n",
      "            Use this to expose configurable parameters via agent.config_specs.\n",
      "        checkpointer: An optional checkpoint saver object. This is used for persisting\n",
      "            the state of the graph (e.g., as chat memory) for a single thread (e.g., a single conversation).\n",
      "        store: An optional store object. This is used for persisting data\n",
      "            across multiple threads (e.g., multiple conversations / users).\n",
      "        interrupt_before: An optional list of node names to interrupt before.\n",
      "            Should be one of the following: \"agent\", \"tools\".\n",
      "            This is useful if you want to add a user confirmation or other interrupt before taking an action.\n",
      "        interrupt_after: An optional list of node names to interrupt after.\n",
      "            Should be one of the following: \"agent\", \"tools\".\n",
      "            This is useful if you want to return directly or run additional processing on an output.\n",
      "        debug: A flag indicating whether to enable debug mode.\n",
      "        version: Determines the version of the graph to create.\n",
      "            Can be one of:\n",
      "\n",
      "            - `\"v1\"`: The tool node processes a single message. All tool\n",
      "                calls in the message are executed in parallel within the tool node.\n",
      "            - `\"v2\"`: The tool node processes a tool call.\n",
      "                Tool calls are distributed across multiple instances of the tool\n",
      "                node using the [Send](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)\n",
      "                API.\n",
      "        name: An optional name for the CompiledStateGraph.\n",
      "            This name will be automatically used when adding ReAct agent graph to another graph as a subgraph node -\n",
      "            particularly useful for building multi-agent systems.\n",
      "\n",
      "    Returns:\n",
      "        A compiled LangChain runnable that can be used for chat interactions.\n",
      "\n",
      "    The \"agent\" node calls the language model with the messages list (after applying the prompt).\n",
      "    If the resulting AIMessage contains `tool_calls`, the graph will then call the [\"tools\"][langgraph.prebuilt.tool_node.ToolNode].\n",
      "    The \"tools\" node executes the tools (1 tool per `tool_call`) and adds the responses to the messages list\n",
      "    as `ToolMessage` objects. The agent node then calls the language model again.\n",
      "    The process repeats until no more `tool_calls` are present in the response.\n",
      "    The agent then returns the full list of messages as a dictionary containing the key \"messages\".\n",
      "\n",
      "    ``` mermaid\n",
      "        sequenceDiagram\n",
      "            participant U as User\n",
      "            participant A as LLM\n",
      "            participant T as Tools\n",
      "            U->>A: Initial input\n",
      "            Note over A: Prompt + LLM\n",
      "            loop while tool_calls present\n",
      "                A->>T: Execute tools\n",
      "                T-->>A: ToolMessage for each tool_calls\n",
      "            end\n",
      "            A->>U: Return final state\n",
      "    ```\n",
      "\n",
      "    Example:\n",
      "        ```python\n",
      "        from langgraph.prebuilt import create_react_agent\n",
      "\n",
      "        def check_weather(location: str) -> str:\n",
      "            '''Return the weather forecast for the specified location.'''\n",
      "            return f\"It's always sunny in {location}\"\n",
      "\n",
      "        graph = create_react_agent(\n",
      "            \"anthropic:claude-3-7-sonnet-latest\",\n",
      "            tools=[check_weather],\n",
      "            prompt=\"You are a helpful assistant\",\n",
      "        )\n",
      "        inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
      "        for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n",
      "            print(chunk)\n",
      "        ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "help(create_react_agent)  # This will show you the accepted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindMate-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
